{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123dd1fd",
   "metadata": {},
   "source": [
    "# model for the domain adaptation:\n",
    "the first model is for the domains and the second for the dust forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069caae3",
   "metadata": {},
   "source": [
    "first try with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_encoder(nn.Module):\n",
    "    def __init__(self,in_channels,n,output_linear):\n",
    "        super(cnn_encoder, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels=in_channels, out_channels=n, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn0 = nn.BatchNorm2d(n)  # BatchNorm after the second convolution\n",
    "        self.relu0 = nn.ReLU()\n",
    "        self.resnet_block0 = ResNetBlock(n, n)\n",
    "        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=n, out_channels=2*n, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(2*n)  # BatchNorm after the first convolution\n",
    "        self.relu = nn.ReLU()# I WIIL APPLY IT AFTER EVERY COV IN THE FORWARD\n",
    "        self.resnet_block1 = ResNetBlock(2*n, 2*n)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=2*n, out_channels=3*n, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(3*n)  # BatchNorm after the second convolution\n",
    "        self.resnet_block2 = ResNetBlock(3*n, 3*n)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=3*n, out_channels=4*n, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(4*n)  # BatchNorm after the second convolution\n",
    "        self.resnet_block3 = ResNetBlock(4*n, 4*n)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=4*n, out_channels=5*n, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(5*n)  # BatchNorm after the second convolution\n",
    "        self.resnet_block4 = ResNetBlock(5*n, 5*n)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=5*n, out_channels=6*n, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(6*n)  # BatchNorm after the second convolution\n",
    "        self.resnet_block5 = ResNetBlock(6*n, 6*n)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "\n",
    "        self.dropout1 = nn.Dropout2d(p=0.1)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.1)\n",
    "\n",
    "        self.fc_input_size = 6*n * 1 * 2  \n",
    "        self.fc1 = nn.Linear(self.fc_input_size, output_linear)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "        #for the domain classifer:\n",
    "        self.fc_input_size = 6*n * 1 * 2  \n",
    "        self.fc3 = nn.Linear(self.fc_input_size ,256 )\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(256, 2)\n",
    "        \n",
    "    def forward(self, x, grl_lambda=1.0):\n",
    "#         x=x.view(-1,153,54,81)\n",
    "        x = self.pool0(self.resnet_block0(self.bn0(self.relu(self.conv0(x)))))\n",
    "        x = self.pool1(self.resnet_block1(self.bn1(self.relu(self.conv1(x)))))\n",
    "        x = self.pool2(self.resnet_block2(self.bn2(self.relu(self.conv2(x)))))\n",
    "        x = self.pool3(self.resnet_block3(self.bn3(self.relu(self.conv3(x)))))\n",
    "        x = self.pool4(self.resnet_block4(self.bn4(self.relu(self.conv4(x)))))\n",
    "        x = self.pool5(self.resnet_block5(self.bn5(self.relu(self.conv5(x)))))\n",
    "        x=self.dropout2(x)\n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "\n",
    "        # Apply gradient reversal\n",
    "        feat_domain = x #GradientReverse.apply(x, grl_lambda)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    " \n",
    "\n",
    "        # Domain classifier part\n",
    "        feat_domain = self.fc3(feat_domain)\n",
    "        feat_domain = self.relu4(feat_domain)\n",
    "        feat_domain = self.fc4(feat_domain)\n",
    "\n",
    "        return x, feat_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc886fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dust_pred(nn.Module):\n",
    "    def __init__(self,linear_input,output_channels):\n",
    "        super(dust_pred, self).__init__()\n",
    "        self.fc1 = nn.Linear(linear_input, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, output_channels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbe78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the trainind func ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_try2(train_dataloader,num_epoch,model_encoder,model_dust,optimizer,scheduler,criterion_label,criterion_sync_time_s,criterion_sync_time_t):\n",
    "    model_dust_list=[]\n",
    "    model_encoder_list=[]\n",
    "    #list_pre_recall_avg=[]\n",
    "    domain_t=torch.full((25,), 1).to(device)\n",
    "    domain_s =  torch.full((25,), 0).to(device)\n",
    "    dict_model_accuracies={}\n",
    "    \n",
    "    for i,epoch in enumerate(range(num_epoch)):\n",
    "        for x_t,x_s,labels,time in tqdm(train_dataloader):\n",
    "            x_t,x_s,labels=x_t.to(device),x_s.to(device),labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output_dust_t,output_domain_t=model_encoder(x_t)\n",
    "            output_dust_s,output_domain_s=model_encoder(x_s)\n",
    "            if x_t.shape==torch.Size([11, 204, 54, 81]) or x_s.shape==torch.Size([11, 204, 54, 81]):\n",
    "                continue\n",
    "            labels=labels.unsqueeze(1)\n",
    "            mask = (x_s.sum([1, 2, 3]) > 0) * (x_t.sum([1, 2, 3])>0)\n",
    "            mask_valid_input=torch.cat([x_s.sum([1, 2, 3]) > 0 , x_t.sum([1, 2, 3])>0])\n",
    "            if any(mask):\n",
    "\n",
    "                domain_loss_s=criterion_sync_time_s(output_domain_s,domain_s)[mask].mean()\n",
    "                domain_loss_t=criterion_sync_time_t(output_domain_t,domain_t)[mask].mean()\n",
    "                \n",
    "            output_cat=torch.cat((output_dust_s,output_dust_t),dim=0)\n",
    "            output_dust=model_dust(output_cat)\n",
    "            label_cat=torch.cat((labels,labels),dim=0)\n",
    "            label_cat=label_cat.squeeze(1)\n",
    "            loss_dust=(criterion_label(output_dust,label_cat)*(label_cat>0)*mask_valid_input).mean()#mask for x_t.sum()>0\n",
    "            \n",
    "            loss_total=1500  *loss_dust -domain_loss_s-domain_loss_t\n",
    "            loss_total.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]-total Loss: {loss_total.item():.4f} ,domain_loss_s: {domain_loss_s.item():.4f},domain_loss_t: {domain_loss_t.item():.4f}, dust_loss:{loss_dust:.4f} \")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            true_positive_target = 0\n",
    "            false_positive_target = 0\n",
    "            false_negative_target = 0\n",
    "            true_negative_target = 0\n",
    "            loss_dust_val=0\n",
    "            #total_count = 0\n",
    "            for i,values in enumerate(val_dataloader):\n",
    "                x_t, x_s, labels,time=values\n",
    "                x_t, x_s, labels = x_t.to(device), x_s.to(device), labels.to(device)\n",
    "                output_dust_t,output_domain_t = model_encoder(x_t)\n",
    "                output = model_dust(output_dust_t)\n",
    "                loss_dust_val+=(criterion_label(output,labels)*(labels>0)).mean()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                true_positive_target += ((predicted == labels) & (labels == 2)).sum().item()\n",
    "                false_positive_target += ((predicted != labels) & (labels == 1)).sum().item()\n",
    "                false_negative_target += ((predicted != labels) & (labels == 2)).sum().item()\n",
    "                true_negative_target += ((predicted == labels) & (labels == 1)).sum().item()\n",
    "                #total_count += labels.size(0)\n",
    "\n",
    "            loss_dust_val=loss_dust_val/(i+1)\n",
    "            print(f'true_pos: {true_positive_target},true_neg: {true_negative_target},false_pos:{false_positive_target},false_neg:{false_negative_target}')\n",
    "            if((true_positive_target + false_positive_target)):\n",
    "                precision_target = 100 * true_positive_target / (true_positive_target + false_positive_target)  # precision\n",
    "            else:\n",
    "                precision_target=torch.tensor([float('nan')])\n",
    "            recall=  100 * true_positive_target / (true_positive_target + false_negative_target)\n",
    "            accuracy=100 * (true_positive_target+true_negative_target) / (true_positive_target + false_negative_target+ true_negative_target + false_positive_target)\n",
    "            recall_precision_avg=((recall+precision_target)/2)\n",
    "            print(f'acc: {accuracy},precision: {precision_target}, recall: {recall}, recall_pre_avg: {recall_precision_avg}')\n",
    "            print()\n",
    "            #print(torch.cuda.memory_summary())\n",
    "            scheduler.step(accuracy)\n",
    "            print(\"Learning rate after:\", optimizer.param_groups[0]['lr'])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd447b",
   "metadata": {},
   "source": [
    "second try , with mse loss between the domains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a6a38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
